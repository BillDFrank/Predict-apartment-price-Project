{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1693149968655,"user":{"displayName":"William Dieter Frank","userId":"11059887809384858726"},"user_tz":-60},"id":"LlvU3lsoE2ai"},"outputs":[],"source":["import os\n","import re\n","import json\n","import pandas as pd\n","import requests\n","import numpy as np\n","from bs4 import BeautifulSoup\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693149968656,"user":{"displayName":"William Dieter Frank","userId":"11059887809384858726"},"user_tz":-60},"id":"WYdtP9alKHZ0"},"outputs":[],"source":["base_url = \"https://www.imovirtual.com/comprar/apartamento/?page=\"\n","num_pages = 3700  # Specify the number of pages to scrape\n","df = []\n","headers = {\n","    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1693149968910,"user":{"displayName":"William Dieter Frank","userId":"11059887809384858726"},"user_tz":-60},"id":"5lbVXoHaNKO7"},"outputs":[],"source":["def scrape_data(url):\n","    response = requests.get(url, headers=headers)\n","    html_content = response.content\n","    soup = BeautifulSoup(html_content, 'html.parser')\n","    article_elements = soup.find_all('article')\n","\n","    titles = []\n","    prices = []\n","    locations = []\n","    rooms = []\n","    areas = []\n","    bathrooms = []\n","    listing_types = []\n","    urls = []\n","\n","\n","    for article_element in article_elements:\n","        # Extract title\n","        title_element = article_element.find('span', class_='offer-item-title')\n","        title = title_element.text.strip() if title_element else np.nan\n","        titles.append(title)\n","\n","        # Extract URL\n","        url_element = article_element.find('a')\n","        url = url_element['href'] if url_element else np.nan\n","        urls.append(url)\n","\n","        # Extract price\n","        price_element = article_element.find(class_='offer-item-price')\n","        price = price_element.text.strip() if price_element else np.nan\n","        prices.append(price)\n","\n","        # Extract location\n","        location_element = article_element.find('p', class_='text-nowrap')\n","        location = location_element.text.strip().split(':')[-1].strip() if location_element else np.nan\n","        locations.append(location)\n","\n","        # Extract room\n","        room_element = article_element.find(class_='offer-item-rooms')\n","        room = room_element.text.strip() if room_element else np.nan\n","        rooms.append(room)\n","\n","        # Extract area\n","        area_element = article_element.find(class_='offer-item-area')\n","        area = area_element.text.strip() if area_element else np.nan\n","        areas.append(area)\n","\n","        # Extract bathrooms and listing type\n","        details_element = article_element.find(class_=['parameters-view', 'params-small'])\n","        bathroom = np.nan\n","        listing_type = np.nan\n","\n","        if details_element:\n","            li_elements = details_element.find_all('li')\n","            for li_element in li_elements:\n","                text = li_element.text.strip()\n","                if 'Casas de Banho' in text:\n","                    bathroom = text.split(':')[-1].strip()\n","                elif text in ['Em construção', 'Usado', 'Novo', 'Remodelado', 'Ruína', 'Para recuperar']:\n","                    listing_type = text\n","\n","        bathrooms.append(bathroom)\n","        listing_types.append(listing_type)\n","\n","\n","    return titles, prices, locations, rooms, areas, bathrooms, listing_types, urls\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3881,"status":"ok","timestamp":1693150008761,"user":{"displayName":"William Dieter Frank","userId":"11059887809384858726"},"user_tz":-60},"id":"aLZZyI47mJ8U","outputId":"20b8c2a0-589c-4a5c-92b1-b4da6f0015a7"},"outputs":[],"source":["\n","titles = []\n","prices = []\n","locations = []\n","rooms = []\n","areas = []\n","bathrooms = []\n","listing_types = []\n","urls = []\n","\n","for page in range(1, num_pages + 1):\n","    print(page)\n","    page_url = base_url + str(page)\n","    (\n","        page_titles,\n","        page_prices,\n","        page_locations,\n","        page_rooms,\n","        page_areas,\n","        page_bathrooms,\n","        page_listing_types,\n","        page_urls,\n","    ) = scrape_data(page_url)\n","\n","    titles += page_titles\n","    prices += page_prices\n","    locations += page_locations\n","    rooms += page_rooms\n","    areas += page_areas\n","    bathrooms += page_bathrooms\n","    listing_types += page_listing_types\n","    urls += page_urls\n","\n","    print(\n","        f\"Page {page}: Titles: {len(page_titles)}, Prices: {len(page_prices)}, ...\"\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1693150012018,"user":{"displayName":"William Dieter Frank","userId":"11059887809384858726"},"user_tz":-60},"id":"kltxFOiV12zS","outputId":"f5df81a4-b19c-47c1-da31-36e86a1e9671"},"outputs":[],"source":["len(listing_types)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1810},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1693150012374,"user":{"displayName":"William Dieter Frank","userId":"11059887809384858726"},"user_tz":-60},"id":"XbfHzim7Nouh","outputId":"1fa77515-f61f-4d95-9736-94b8145f0a01"},"outputs":[],"source":["# Create a DataFrame\n","data = {\n","    \"URL\": urls,\n","    \"Titles\": titles,\n","    \"Price\": prices,\n","    \"Location\": locations,\n","    \"Rooms\": rooms,\n","    \"Areas\": areas,\n","    \"Bathrooms\": bathrooms,\n","    \"Listing Type\": listing_types,\n","}\n","\n","df = pd.DataFrame(data)\n","# Print the DataFrame\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":279,"status":"ok","timestamp":1693152392452,"user":{"displayName":"William Dieter Frank","userId":"11059887809384858726"},"user_tz":-60},"id":"XcBQbllrJvqp"},"outputs":[],"source":["df.to_csv(\"Files/apartmentsPortugal.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"2oLu0hOuU5ba"},"outputs":[],"source":["# Load your DataFrame containing property URLs\n","df = pd.read_csv('Files/apartmentsPortugal.csv')\n","\n","headers = {\n","    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n","}\n","\n","for property_number, url in enumerate(df['URL']):\n","    # Send a request to the URL\n","    response = requests.get(url, headers=headers)\n","\n","    if response.status_code == 200:\n","        soup = BeautifulSoup(response.content, 'html.parser')\n","\n","\n","\n","        # Find the script tag containing image data\n","        script_elements = soup.find_all('script')\n","\n","        for script_element in script_elements:\n","            script_content = script_element.string\n","            if script_content:\n","                # Use regex to extract image URLs from the script\n","                image_urls = re.findall(r'\"large\":\"(https://ireland\\.apollo\\.olxcdn\\.com[^\"]+)\"', script_content)\n","                if image_urls:\n","                    property_folder = f'Files/PropertiesImages/Property{property_number}'\n","                    os.makedirs(property_folder, exist_ok=True)\n","\n","                    for index, image_url in enumerate(image_urls):\n","                        image_response = requests.get(image_url)\n","                        if image_response.status_code == 200:\n","                            image_extension = \"webp\"  # Assuming images are in webp format\n","                            image_filename = f\"Property{property_number}-Image{index + 1}.{image_extension}\"\n","                            image_path = os.path.join(property_folder, image_filename)\n","\n","                            with open(image_path, 'wb') as f:\n","                                f.write(image_response.content)\n","                            print(f\"Image {index + 1} saved to {image_path}\")\n","                        else:\n","                            print(f\"Failed to download image {index + 1}\")\n","                else:\n","                    print(\"No image URLs found in script\")\n","    else:\n","        print(f\"Failed to retrieve property page for {url}\")\n","\n","print(\"Images downloaded and saved for all properties.\")\n"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"}},"nbformat":4,"nbformat_minor":0}
