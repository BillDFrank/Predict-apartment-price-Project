{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = \"Files\"\n",
    "LISTINGS_CSV = os.path.join(BASE_DIR, \"apartmentsPortugal.csv\")\n",
    "CONSOLIDATED_CSV = os.path.join(BASE_DIR, \"Consolidated.csv\")\n",
    "BASE_URL = \"https://www.imovirtual.com/comprar/apartamento/?page=\"\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(BASE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(page_num):\n",
    "    \"\"\"Scrape data from a single listing page with columns matching consolidated.csv\"\"\"\n",
    "    url = f\"{BASE_URL}{page_num}\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve page {page_num}. Status code: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    articles = soup.find_all('article', {'data-cy': 'listing-item'})\n",
    "    \n",
    "    if not articles:\n",
    "        return None\n",
    "    \n",
    "    # Initialize all columns present in consolidated.csv\n",
    "    data = {\n",
    "        'URL': [],\n",
    "        'Titles': [],\n",
    "        'Price': [],\n",
    "        'Location': [],\n",
    "        'Rooms': [],\n",
    "        'Areas': [],\n",
    "        'Bathrooms': [],\n",
    "        'Listing Type': [],\n",
    "        'Useful area': [],\n",
    "        'Gross area': [],\n",
    "        'Construction year': [],\n",
    "        'Energetic certificate': [],\n",
    "        'Enterprise': [],\n",
    "        'DateScraped': [],\n",
    "        'Page': [],\n",
    "        'Description': []\n",
    "    }\n",
    "    \n",
    "    scrape_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    for article in articles:\n",
    "        # Existing fields\n",
    "        data['URL'].append(\n",
    "            f\"https://www.imovirtual.com{article.find('a')['href']}\" \n",
    "            if article.find('a') else np.nan\n",
    "        )\n",
    "        data['Titles'].append(\n",
    "            article.find('p', class_='css-u3orbr').text.strip() \n",
    "            if article.find('p', class_='css-u3orbr') else np.nan\n",
    "        )\n",
    "        data['Price'].append(\n",
    "            article.find('span', class_='css-2bt9f1').text.strip() \n",
    "            if article.find('span', class_='css-2bt9f1') else np.nan\n",
    "        )\n",
    "        data['Location'].append(\n",
    "            article.find('p', class_='css-42r2ms').text.strip() \n",
    "            if article.find('p', class_='css-42r2ms') else np.nan\n",
    "        )\n",
    "        \n",
    "        # Rooms and Areas\n",
    "        dl = article.find('dl', class_='css-12dsp7a')\n",
    "        if dl:\n",
    "            dt_dd = {dt.text.strip(): dd.text.strip() \n",
    "                    for dt, dd in zip(dl.find_all('dt'), dl.find_all('dd'))}\n",
    "            data['Rooms'].append(dt_dd.get('Tipologia', np.nan))\n",
    "            area = dt_dd.get('Zona', np.nan)\n",
    "            data['Areas'].append(area.split()[0] if area else np.nan)\n",
    "        else:\n",
    "            data['Rooms'].append(np.nan)\n",
    "            data['Areas'].append(np.nan)\n",
    "        \n",
    "        # Empty columns to be filled in Part 2\n",
    "        data['Bathrooms'].append(np.nan)\n",
    "        data['Listing Type'].append(np.nan)\n",
    "        data['Useful area'].append(np.nan)\n",
    "        data['Gross area'].append(np.nan)\n",
    "        data['Construction year'].append(np.nan)\n",
    "        data['Energetic certificate'].append(np.nan)\n",
    "        data['Enterprise'].append(np.nan)\n",
    "        data['Description'].append(np.nan)\n",
    "        data['DateScraped'].append(scrape_date)\n",
    "        data['Page'].append(page_num)\n",
    "    \n",
    "    # Validate lengths\n",
    "    lengths = [len(v) for v in data.values()]\n",
    "    if len(set(lengths)) != 1:\n",
    "        print(f\"Data length mismatch in page {page_num}: {lengths}\")\n",
    "        return None\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def scrape_listings(num_pages):\n",
    "    \"\"\"Scrape multiple listing pages with resume support.\"\"\"\n",
    "    if os.path.exists(LISTINGS_CSV):\n",
    "        df_existing = pd.read_csv(LISTINGS_CSV)\n",
    "        start_page = df_existing['Page'].max() + 1 if 'Page' in df_existing.columns else 1\n",
    "    else:\n",
    "        start_page = 1\n",
    "    \n",
    "    end_page = start_page + num_pages - 1\n",
    "    session = requests.Session()\n",
    "    \n",
    "    for page in range(start_page, end_page + 1):\n",
    "        print(f\"Scraping page {page}...\")\n",
    "        df_page = scrape_page(page)\n",
    "        if df_page is None:\n",
    "            print(f\"No data on page {page}. Stopping.\")\n",
    "            break\n",
    "        \n",
    "        # Save incrementally\n",
    "        df_page.to_csv(LISTINGS_CSV, mode='a', header=not os.path.exists(LISTINGS_CSV), index=False)\n",
    "        print(f\"Page {page} saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_details():\n",
    "    \"\"\"Scrape detailed information with corrected column names\"\"\"\n",
    "    df = pd.read_csv(LISTINGS_CSV)\n",
    "    \n",
    "    # Identify URLs needing processing\n",
    "    mask = df['Construction year'].isna() | df['Bathrooms'].isna()\n",
    "    indices = df[mask].index.tolist()\n",
    "    \n",
    "    ua = UserAgent()\n",
    "    session = requests.Session()\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        try:\n",
    "            url = df.loc[idx, 'URL']\n",
    "            response = session.get(url, headers={'User-Agent': ua.random}, timeout=10)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "                # Get useful area (default to \"N/A\" if not available)\n",
    "                df.at[idx, 'Useful area'] = \"N/A\"\n",
    "\n",
    "                # Get gross area, rooms, and bathrooms\n",
    "                try:\n",
    "                    buttons = soup.find_all('button', class_='eezlw8k1 css-ds0a69')\n",
    "                    if len(buttons) >= 3:\n",
    "                        area_div = buttons[0].find('div', class_='css-1ftqasz')\n",
    "                        df.at[idx, 'Gross area'] = area_div.get_text(strip=True) if area_div else \"N/A\"\n",
    "\n",
    "                        rooms_div = buttons[1].find('div', class_='css-1ftqasz')\n",
    "                        df.at[idx, 'Rooms'] = rooms_div.get_text(strip=True) if rooms_div else \"N/A\"\n",
    "\n",
    "                        bathrooms_div = buttons[2].find('div', class_='css-1ftqasz')\n",
    "                        df.at[idx, 'Bathroom'] = bathrooms_div.get_text(strip=True) if bathrooms_div else \"N/A\"\n",
    "                    else:\n",
    "                        df.at[idx, 'Gross area'] = \"N/A\"\n",
    "                        df.at[idx, 'Rooms'] = \"N/A\"\n",
    "                        df.at[idx, 'Bathroom'] = \"N/A\"\n",
    "                except AttributeError:\n",
    "                    df.at[idx, 'Gross area'] = \"N/A\"\n",
    "                    df.at[idx, 'Rooms'] = \"N/A\"\n",
    "                    df.at[idx, 'Bathroom'] = \"N/A\"\n",
    "\n",
    "                # Get construction year\n",
    "                try:\n",
    "                    divs = soup.find_all('div', class_='css-t7cajz e15n0fyo1')\n",
    "                    construction_year = \"N/A\"\n",
    "                    for div in divs:\n",
    "                        p_elements = div.find_all('p', class_='e15n0fyo2 css-nlohq6')\n",
    "                        for i, p in enumerate(p_elements):\n",
    "                            if \"Ano de construção\" in p.get_text(strip=True):\n",
    "                                if i + 1 < len(p_elements):\n",
    "                                    construction_year = p_elements[i + 1].get_text(strip=True)\n",
    "                                break\n",
    "                        if construction_year != \"N/A\":\n",
    "                            break\n",
    "                    df.at[idx, 'Construction year'] = construction_year\n",
    "                except (AttributeError, IndexError):\n",
    "                    df.at[idx, 'Construction year'] = \"N/A\"\n",
    "\n",
    "                # Get energetic certificate\n",
    "                try:\n",
    "                    energetic_certificate = \"N/A\"\n",
    "                    for div in divs:\n",
    "                        p_elements = div.find_all('p', class_='e15n0fyo2 css-nlohq6')\n",
    "                        for i, p in enumerate(p_elements):\n",
    "                            if \"Certificado energético\" in p.get_text(strip=True):\n",
    "                                if i + 1 < len(p_elements):\n",
    "                                    energetic_certificate = p_elements[i + 1].get_text(strip=True)\n",
    "                                break\n",
    "                        if energetic_certificate != \"N/A\":\n",
    "                            break\n",
    "                    df.at[idx, 'Energetic certificate'] = energetic_certificate\n",
    "                except (AttributeError, IndexError):\n",
    "                    df.at[idx, 'Energetic certificate'] = \"N/A\"\n",
    "\n",
    "                # Save progress every 50 URLs\n",
    "                if (i + 1) % 50 == 0:\n",
    "                    df.to_csv(LISTINGS_CSV, index=False)\n",
    "\n",
    "                time.sleep(random.uniform(0.5, 1.5))\n",
    "\n",
    "            else:\n",
    "                print(f\"Skipping {url} due to status code {response.status_code}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {url}: {str(e)}\")\n",
    "\n",
    "    \n",
    "    df.to_csv(LISTINGS_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data():\n",
    "    \"\"\"Merge data while preserving existing structure\"\"\"\n",
    "    if os.path.exists(CONSOLIDATED_CSV):\n",
    "        consolidated = pd.read_csv(CONSOLIDATED_CSV)\n",
    "    else:\n",
    "        consolidated = pd.DataFrame(columns=[\n",
    "            'URL', 'Titles', 'Price', 'Location', 'Rooms', 'Areas',\n",
    "            'Bathrooms', 'Listing Type', 'Useful area', 'Gross area',\n",
    "            'Construction year', 'Energetic certificate', 'Enterprise',\n",
    "            'DateScraped', 'Page', 'Description'\n",
    "        ])\n",
    "    \n",
    "    new_data = pd.read_csv(LISTINGS_CSV)\n",
    "    \n",
    "    # Convert numeric columns\n",
    "    numeric_cols = ['Construction year', 'Page']\n",
    "    for col in numeric_cols:\n",
    "        new_data[col] = pd.to_numeric(new_data[col], errors='coerce')\n",
    "    \n",
    "    # Merge and deduplicate\n",
    "    combined = pd.concat([consolidated, new_data], ignore_index=True)\n",
    "    combined = combined.drop_duplicates('URL', keep='last')\n",
    "    \n",
    "    # Remove temporary columns\n",
    "    combined = combined.loc[:, ~combined.columns.str.contains('Unnamed')]\n",
    "    \n",
    "    combined.to_csv(CONSOLIDATED_CSV, index=False)\n",
    "    print(f\"Merged data saved. Total records: {len(combined)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 2...\n",
      "Page 2 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_67424\\2295770096.py:4: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  consolidated = pd.read_csv(CONSOLIDATED_CSV)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved. Total records: 90076\n"
     ]
    }
   ],
   "source": [
    "scrape_listings(1)\n",
    "scrape_details()\n",
    "merge_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_67424\\872192564.py:1: DtypeWarning: Columns (13,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined = pd.read_csv(\"Files/Consolidated.csv\", index_col=False)\n"
     ]
    }
   ],
   "source": [
    "combined = pd.read_csv(\"Files/Consolidated.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90076 entries, 0 to 90075\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   URL                    90076 non-null  object \n",
      " 1   Titles                 90076 non-null  object \n",
      " 2   Price                  90076 non-null  object \n",
      " 3   Location               90076 non-null  object \n",
      " 4   Rooms                  90060 non-null  object \n",
      " 5   Areas                  90076 non-null  object \n",
      " 6   Bathrooms              81941 non-null  object \n",
      " 7   Listing Type           62115 non-null  object \n",
      " 8   Useful area            89747 non-null  object \n",
      " 9   Gross area             71747 non-null  object \n",
      " 10  Construction year      49756 non-null  float64\n",
      " 11  Energetic certificate  89641 non-null  object \n",
      " 12  Enterprise             80494 non-null  object \n",
      " 13  DateScraped            76 non-null     object \n",
      " 14  Page                   76 non-null     float64\n",
      " 15  Description            0 non-null      float64\n",
      " 16  Bathroom               50 non-null     object \n",
      "dtypes: float64(3), object(14)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Titles</th>\n",
       "      <th>Price</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Areas</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Listing Type</th>\n",
       "      <th>Useful area</th>\n",
       "      <th>Gross area</th>\n",
       "      <th>Construction year</th>\n",
       "      <th>Energetic certificate</th>\n",
       "      <th>Enterprise</th>\n",
       "      <th>DateScraped</th>\n",
       "      <th>Page</th>\n",
       "      <th>Description</th>\n",
       "      <th>Bathroom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90071</th>\n",
       "      <td>https://www.imovirtual.com/pt/anuncio/apartame...</td>\n",
       "      <td>Apartamento T2 no centro de Oliveira do Bairro</td>\n",
       "      <td>192 000 €</td>\n",
       "      <td>Oliveira do Bairro, Oliveira do Bairro, Aveiro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90072</th>\n",
       "      <td>https://www.imovirtual.com/pt/anuncio/t3-a-5-m...</td>\n",
       "      <td>T3 a 5 Minutos da estaçao dos Barcos</td>\n",
       "      <td>274 000 €</td>\n",
       "      <td>Barreiro e Lavradio, Barreiro, Setúbal</td>\n",
       "      <td>T3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100m²</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90073</th>\n",
       "      <td>https://www.imovirtual.com/pt/anuncio/andar-mo...</td>\n",
       "      <td>Andar Moradia T3 | Maia | Terraço | Box | Metr...</td>\n",
       "      <td>439 000 €</td>\n",
       "      <td>Rua das Caleiras, Centro, Cidade da Maia, Maia...</td>\n",
       "      <td>T3</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144m²</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>B-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90074</th>\n",
       "      <td>https://www.imovirtual.com/pt/anuncio/apartame...</td>\n",
       "      <td>Apartamento T1 | Em construção | Terraço | Var...</td>\n",
       "      <td>295 000 €</td>\n",
       "      <td>Arca d'Água - Campo Lindo - Vale Formoso, Para...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90075</th>\n",
       "      <td>https://www.imovirtual.com/pt/anuncio/apartame...</td>\n",
       "      <td>Apartamento T3 para venda</td>\n",
       "      <td>325 000 €</td>\n",
       "      <td>Rua Doutor Alfredo Pires Miranda - Bairro do F...</td>\n",
       "      <td>T3</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137m²</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     URL  \\\n",
       "90071  https://www.imovirtual.com/pt/anuncio/apartame...   \n",
       "90072  https://www.imovirtual.com/pt/anuncio/t3-a-5-m...   \n",
       "90073  https://www.imovirtual.com/pt/anuncio/andar-mo...   \n",
       "90074  https://www.imovirtual.com/pt/anuncio/apartame...   \n",
       "90075  https://www.imovirtual.com/pt/anuncio/apartame...   \n",
       "\n",
       "                                                  Titles      Price  \\\n",
       "90071     Apartamento T2 no centro de Oliveira do Bairro  192 000 €   \n",
       "90072               T3 a 5 Minutos da estaçao dos Barcos  274 000 €   \n",
       "90073  Andar Moradia T3 | Maia | Terraço | Box | Metr...  439 000 €   \n",
       "90074  Apartamento T1 | Em construção | Terraço | Var...  295 000 €   \n",
       "90075                          Apartamento T3 para venda  325 000 €   \n",
       "\n",
       "                                                Location Rooms  Areas  \\\n",
       "90071     Oliveira do Bairro, Oliveira do Bairro, Aveiro   NaN  84.95   \n",
       "90072             Barreiro e Lavradio, Barreiro, Setúbal    T3  100.0   \n",
       "90073  Rua das Caleiras, Centro, Cidade da Maia, Maia...    T3  144.0   \n",
       "90074  Arca d'Água - Campo Lindo - Vale Formoso, Para...   NaN   55.0   \n",
       "90075  Rua Doutor Alfredo Pires Miranda - Bairro do F...    T3  137.0   \n",
       "\n",
       "      Bathrooms Listing Type Useful area Gross area  Construction year  \\\n",
       "90071       NaN          NaN         NaN        NaN             2026.0   \n",
       "90072       NaN          NaN         NaN      100m²                NaN   \n",
       "90073       NaN          NaN         NaN      144m²             2005.0   \n",
       "90074       NaN          NaN         NaN        NaN             2024.0   \n",
       "90075       NaN          NaN         NaN      137m²             2025.0   \n",
       "\n",
       "      Energetic certificate Enterprise DateScraped  Page  Description Bathroom  \n",
       "90071                     A        NaN  2025-01-28   2.0          NaN      NaN  \n",
       "90072                     D        NaN  2025-01-28   2.0          NaN        2  \n",
       "90073                    B-        NaN  2025-01-28   2.0          NaN        2  \n",
       "90074                     B        NaN  2025-01-28   2.0          NaN      NaN  \n",
       "90075                     A        NaN  2025-01-28   2.0          NaN        3  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
